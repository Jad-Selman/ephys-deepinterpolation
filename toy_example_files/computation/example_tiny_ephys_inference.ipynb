{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84c3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepinterpolation.generic import JsonSaver, ClassLoader\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cab4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60153601",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    generator_param = {}\n",
    "    inferrence_param = {}\n",
    "\n",
    "    # We are reusing the data generator for training here. Some parameters\n",
    "    # like steps_per_epoch are irrelevant but currently needs to be provided\n",
    "    generator_param[\"type\"] = \"generator\"\n",
    "    generator_param[\"name\"] = \"EphysGenerator\"\n",
    "    generator_param[\"pre_post_frame\"] = 30\n",
    "    generator_param[\"pre_post_omission\"] = 1\n",
    "    generator_param[\n",
    "        \"steps_per_epoch\"\n",
    "    ] = -1\n",
    "    # No steps necessary for inference as epochs are not relevant.\n",
    "    # -1 deactivate it.\n",
    "    \n",
    "generator_param[\"train_path\"] = os.path.join(\n",
    "        \"..\",\n",
    "        \"unet_single_ephys_1024_mean_absolute_error_2022_11_11_16_55_2022_11_11_16_55\",\n",
    "        \"2022_11_11_16_55_unet_single_ephys_1024_mean_absolute_error_2022_11_11_16_55_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8455f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_param[\"train_path\"] = os.path.join(\n",
    "        \"..\",\n",
    "        \"unet_single_ephys_1024_mean_absolute_error_2022_11_11_16_55_2022_11_11_16_55\",\n",
    "        \"2022_11_11_16_55_unet_single_ephys_1024_mean_absolute_error_2022_11_11_16_55_model.h5\")\n",
    "\n",
    "generator_param[\"batch_size\"] = 100\n",
    "generator_param[\"start_frame\"] = 100\n",
    "generator_param[\"end_frame\"] = 500  # -1 to go until the end.\n",
    "generator_param[\n",
    "        \"randomize\"\n",
    "    ] = 0\n",
    "# This is important to keep the order and avoid the\n",
    "    # randomization used during training\n",
    "\n",
    "inferrence_param[\"type\"] = \"inferrence\"\n",
    "inferrence_param[\"name\"] = \"core_inferrence\"\n",
    "\n",
    "# Replace this path to where you stored your model\n",
    "inferrence_param[\n",
    "        \"model_path\"\n",
    "    ] = \"/Users/jadse/deepinterpolation/unet_single_ephys_1024_mean_absolute_error_2022_11_11_16_55_2022_11_11_16_55/2022_11_11_16_55_unet_single_ephys_1024_mean_absolute_error_2022_11_11_16_55_model.h5\"\n",
    "\n",
    "    # Replace this path to where you want to store your output file\n",
    "inferrence_param[\n",
    "        \"output_file\"\n",
    "    ] = \"/Users/jadse/deepinterpolation/results of inf+new model/ephys_tiny_continuous_deep_interpolation.h5\"\n",
    "\n",
    "jobdir = \"/Users/jadse/deepinterpolation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be8a175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(jobdir)\n",
    "except Exception:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "path_generator = os.path.join(jobdir, \"generator.json\")\n",
    "json_obj = JsonSaver(generator_param)\n",
    "json_obj.save_json(path_generator)\n",
    "\n",
    "path_infer = os.path.join(jobdir, \"inferrence.json\")\n",
    "json_obj = JsonSaver(inferrence_param)\n",
    "json_obj.save_json(path_infer)\n",
    "\n",
    "generator_obj = ClassLoader(path_generator)\n",
    "data_generator = generator_obj.find_and_build()(path_generator)\n",
    "\n",
    "inferrence_obj = ClassLoader(path_infer)\n",
    "inferrence_class = inferrence_obj.find_and_build()(path_infer,\n",
    "                                                       data_generator)\n",
    "\n",
    "# Except this to be slow on a laptop without GPU. Inference needs\n",
    "# parallelization to be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11e91986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 119ms/step\n",
      "4/4 [==============================] - 0s 108ms/step\n",
      "4/4 [==============================] - 0s 82ms/step\n",
      "4/4 [==============================] - 0s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "inferrence_class.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187b412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
