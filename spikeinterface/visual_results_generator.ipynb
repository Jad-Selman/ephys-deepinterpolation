{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# the generator is in the \"spikeinterface_generator.py\"\n",
    "from spikeinterface_generator import SpikeInterfaceGenerator\n",
    "from deepinterpolation.trainor_collection import core_trainer\n",
    "from deepinterpolation.generic import ClassLoader\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of data generation in spike interface\n",
    "folder_path = \"/home/buccino/data/Neuropixels2.0_Recording/open-ephys-np2/595262_2022-02-22_16-47-26/\"\n",
    "recording = se.read_openephys(folder_path)\n",
    "\n",
    "rec_f = spre.bandpass_filter(recording)\n",
    "rec_norm = spre.zscore(rec_f)\n",
    "\n",
    "sw.plot_timeseries(rec_f, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (from core_trainor class)\n",
    "output_folder = Path(\"test_training_hp_filter_t20s_v0.5s\")\n",
    "output_folder.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference Vusalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"test_training_hp_filter_t20s_v0.5s/first_test_unet_single_ephys_1024_mean_absolute_error-0030-0.7303.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_START_S = 0\n",
    "TRAINING_END_S = 20\n",
    "TESTING_START_S = 100\n",
    "TESTING_END_S = 100.1\n",
    "DESIRED_SHAPE = (192, 2)\n",
    "\n",
    "pre_frame = 30\n",
    "post_frame = 30\n",
    "pre_post_omission = 1\n",
    "\n",
    "start_frame_training = int(TRAINING_START_S * rec_norm.sampling_frequency)\n",
    "end_frame_training = int(TRAINING_END_S * rec_norm.sampling_frequency)\n",
    "start_frame_test = int(TESTING_START_S * rec_norm.sampling_frequency) \n",
    "end_frame_test = int(TESTING_END_S * rec_norm.sampling_frequency)\n",
    "\n",
    "training_data_generator = SpikeInterfaceGenerator(rec_norm, zscore=False, \n",
    "                                                  pre_frame=pre_frame, post_frame=post_frame,\n",
    "                                                  pre_post_omission=pre_post_omission,\n",
    "                                                  start_frame=start_frame_training,\n",
    "                                                  end_frame=end_frame_training,\n",
    "                                                  desired_shape=DESIRED_SHAPE)\n",
    "test_data_generator = SpikeInterfaceGenerator(rec_norm, zscore=False,\n",
    "                                              pre_frame=pre_frame, post_frame=post_frame,\n",
    "                                              pre_post_omission=pre_post_omission,\n",
    "                                              start_frame=start_frame_test,\n",
    "                                              end_frame=end_frame_test,\n",
    "                                              steps_per_epoch=-1,\n",
    "                                              desired_shape=DESIRED_SHAPE)\n",
    "\n",
    "# Those are parameters used for the network topology\n",
    "network_params = dict()\n",
    "network_params[\"type\"] = \"network\"\n",
    "# Name of network topology in the collection\n",
    "network_params[\"name\"] = \"unet_single_ephys_1024\"\n",
    "\n",
    "network_json_path = output_folder / \"network_params.json\"\n",
    "with open(network_json_path, \"w\") as f:\n",
    "    json.dump(network_params, f)\n",
    "\n",
    "\n",
    "\n",
    "training_params = dict()\n",
    "training_params[\"loss\"] = \"mean_absolute_error\"\n",
    "\n",
    "training_params[\"model_string\"] = f\"{network_params['name']}_{training_params['loss']}\"\n",
    "training_params[\"output_dir\"] = str(output_folder)\n",
    "# We pass on the uid\n",
    "training_params[\"run_uid\"] = \"first_test\"\n",
    "\n",
    "# We convert to old schema\n",
    "training_params[\"nb_gpus\"] = 1\n",
    "training_params[\"type\"] = \"trainer\"\n",
    "training_params[\"steps_per_epoch\"] = 10\n",
    "training_params[\"period_save\"] = 5\n",
    "training_params[\"apply_learning_decay\"] = 0\n",
    "training_params[\"nb_times_through_data\"] = 1\n",
    "training_params[\"learning_rate\"] = 0.0001\n",
    "training_params[\"pre_post_frame\"] = 1\n",
    "training_params[\"loss\"] = \"mean_absolute_error\"\n",
    "training_params[\"nb_workers\"] = 2\n",
    "training_params[\"caching_validation\"] = False\n",
    "\n",
    "training_json_path = output_folder / \"training_params.json\"\n",
    "with open(training_json_path, \"w\") as f:\n",
    "    json.dump(training_params, f)\n",
    "\n",
    "network_obj = ClassLoader(network_json_path)\n",
    "data_network = network_obj.find_and_build()(network_json_path)\n",
    "\n",
    "training_class = core_trainer(\n",
    "    training_data_generator, test_data_generator, data_network,\n",
    "    training_json_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_params[\"run_uid\"] = \"first_test\"\n",
    "#network_params[\"name\"] = \"unet_single_ephys_1024\"\n",
    "#training_params[\"loss\"] = \"mean_absolute_error\"\n",
    "training_params[\"model_string\"] = f\"{network_params['name']}_{training_params['loss']}\"\n",
    "model_path = output_folder / f\"{training_params['run_uid']}_{training_params['model_string']}_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.models.load_model(filepath=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape (this will need to be done at inference)\n",
    "desired_shape = (192, 2)\n",
    "network_input_shape = model.get_config()[\"layers\"][0][\"config\"][\"batch_input_shape\"]\n",
    "assert network_input_shape[1:] == desired_shape + (pre_frame + post_frame,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input, original_data = test_data_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(sample_input)\n",
    "output_data = test_data_generator.reshape_output(output)\n",
    "input_data = original_data.squeeze().reshape(-1, recording.get_num_channels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "plt.title(\"Spikeinterface-training_Neuropixels2.0_hp-filter_600epochs_600,000Samples\", fontsize=6, loc='right')\n",
    "axs[0].imshow(input_data.T, origin=\"lower\", cmap=\"RdGy_r\")\n",
    "axs[1].imshow(output_data.T, origin=\"lower\", cmap=\"RdGy_r\")\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Acquisition Channels')\n",
    "#plt.savefig(\"alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef5c68faf8204404377e87c99532205ec20c8c2f7ecfea9ab61e3177e8a272dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
