{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is responsible of:\n",
    "- creating different deepinterpolated models of the recording after filtering and zscoring the input data in 3 different condition (bandpass then deepinterpolation, deepinterpolation then bandpassing, and highpass filtering then deepinterpolation).\n",
    "- conducting statistical analysis of the preditcted recording with respect to the groundtruth data: visualizing groundtruth data, predicted data, and the difference between them, power spectrum density using welch method, covariance matrices, Kolmogoroc-Smirnov test of the differnce for whitness testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#from ...core import BaseRecording\n",
    "#from baserecording import BaseRecording\n",
    "\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "\n",
    "#from deepinterpolation.trainor_collection import core_trainer\n",
    "#from deepinterpolation.network_collection import unet_single_ephys_1024\n",
    "#from deepinterpolation.generic import ClassLoader\n",
    "\n",
    "from spikeinterface_generator import SpikeInterfaceRecordingSegmentGenerator\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from spikeinterface.core.core_tools import define_function_from_class\n",
    "from spikeinterface.preprocessing.basepreprocessor import BasePreprocessor, BasePreprocessorSegment\n",
    "from spikeinterface.preprocessing.zero_channel_pad import ZeroChannelPaddedRecording\n",
    "from spikeinterface.core import get_random_data_chunks\n",
    "from spikeinterface.preprocessing.normalize_scale import ScaleRecordingSegment, NormalizeByQuantileRecording, ScaleRecording, CenterRecording, ZScoreRecording\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "#from spikeinterface.preprocessing import get_random_data_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of the training_bp_filter_t20s_v0.5s\n",
    "model_path = \"/home/buccino/codes/ephys-deepinterpolation/spikeinterface/deepinterpolation_recording/trained_models/test_training_bp_filter_t20s_v0.5s/first_test_unet_single_ephys_1024_mean_absolute_error_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of the recording\n",
    "folder_path = Path(\"/home/buccino/data/Neuropixels2.0_Recording/open-ephys-np2/595262_2022-02-22_16-47-26/\")\n",
    "output_folder = Path(\"recording_saved\")\n",
    "if output_folder.is_dir():\n",
    "    shutil.rmtree(output_folder)\n",
    "recording = se.read_openephys(folder_path)\n",
    "recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_hp = spre.highpass_filter(recording)\n",
    "recording_bp = spre.bandpass_filter(recording)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating gain and offset \"no_filter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = get_random_data_chunks(recording)\n",
    "means = np.mean(random_data, axis=0)\n",
    "means = means[None, :]\n",
    "stds = np.std(random_data, axis=0)\n",
    "stds = stds[None, :] \n",
    "gain = 1 / stds\n",
    "gain_no_filter= gain\n",
    "offset = -means / stds\n",
    "offset_no_filter= offset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating gain and offset \"bandpass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = get_random_data_chunks(recording_bp)\n",
    "means = np.mean(random_data, axis=0)\n",
    "means = means[None, :]\n",
    "stds = np.std(random_data, axis=0)\n",
    "stds = stds[None, :] \n",
    "gain = 1 / stds\n",
    "gain_bp_filter= gain\n",
    "offset = -means / stds\n",
    "offset_bp_filter= offset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating gain and offset \"highpass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = get_random_data_chunks(recording_hp)\n",
    "means = np.mean(random_data, axis=0)\n",
    "means = means[None, :]\n",
    "stds = np.std(random_data, axis=0)\n",
    "stds = stds[None, :] \n",
    "gain = 1 / stds\n",
    "gain_hp_filter= gain\n",
    "offset = -means / stds\n",
    "offset_hp_filter= offset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization using zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_norm_no = spre.zscore(recording)\n",
    "rec_norm_hp = spre.zscore(recording_hp)\n",
    "rec_norm_bp = spre.zscore(recording_bp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining needed classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_tf(use_gpu=True, disable_tf_logger=True):\n",
    "    try:\n",
    "        import_tf(use_gpu, disable_tf_logger)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "    \n",
    "def import_tf(use_gpu=True, disable_tf_logger=True):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    if not use_gpu:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "    if disable_tf_logger:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "        tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepInterpolatedRecordingSegment(BasePreprocessorSegment):\n",
    "\n",
    "    def __init__(self, recording_segment, model,\n",
    "                 pre_frames, post_frames, pre_post_omission,\n",
    "                 batch_size, use_gpu, desired_shape,\n",
    "                 disable_tf_logger):\n",
    "        BasePreprocessorSegment.__init__(self, recording_segment)\n",
    "\n",
    "        self.model = model\n",
    "        self.pre_frames = pre_frames\n",
    "        self.post_frames = post_frames\n",
    "        self.pre_post_omission = pre_post_omission\n",
    "        self.batch_size = batch_size\n",
    "        self.use_gpu = use_gpu\n",
    "        self.desired_shape=desired_shape\n",
    "\n",
    "\n",
    "        # creating class dynamically to use the imported TF with GPU enabled/disabled based on the use_gpu flag\n",
    "        # self.SpikeInterfaceGenerator = SpikeInterfaceRecordingSegmentGenerator #define_input_generator_class( use_gpu, disable_tf_logger)\n",
    "\n",
    "    def get_traces(self, start_frame, end_frame, channel_indices):\n",
    "        n_frames = self.parent_recording_segment.get_num_samples()\n",
    "\n",
    "        if start_frame == None:\n",
    "            start_frame = 0\n",
    "\n",
    "        if end_frame == None:\n",
    "            end_frame = n_frames\n",
    "\n",
    "        # for frames that lack full training data (i.e. pre and post frames including omissinos),\n",
    "        # just return uninterpolated\n",
    "        if start_frame < self.pre_frames+self.pre_post_omission:\n",
    "            true_start_frame = self.pre_frames+self.pre_post_omission\n",
    "            array_to_append_front = self.parent_recording_segment.get_traces(start_frame=0,\n",
    "                                                                             end_frame=true_start_frame,\n",
    "                                                                             channel_indices=channel_indices)\n",
    "        else:\n",
    "            true_start_frame = start_frame\n",
    "\n",
    "        if end_frame > n_frames-self.post_frames-self.pre_post_omission:\n",
    "            true_end_frame = n_frames-self.post_frames-self.pre_post_omission\n",
    "            array_to_append_back = self.parent_recording_segment.get_traces(start_frame=true_end_frame,\n",
    "                                                                            end_frame=n_frames,\n",
    "                                                                            channel_indices=channel_indices)\n",
    "        else:\n",
    "            true_end_frame = end_frame\n",
    "\n",
    "        # instantiate an input generator that can be passed directly to model.predict\n",
    "        input_generator = SpikeInterfaceRecordingSegmentGenerator(recording_segment=self.parent_recording_segment,\n",
    "                                                                  start_frame=true_start_frame,\n",
    "                                                                  end_frame=true_end_frame,\n",
    "                                                                  pre_frame=self.pre_frames,\n",
    "                                                                  post_frame=self.post_frames,\n",
    "                                                                  pre_post_omission=self.pre_post_omission,\n",
    "                                                                  batch_size=self.batch_size)\n",
    "        input_generator.randomize = False\n",
    "        input_generator._calculate_list_samples(input_generator.total_samples)\n",
    "        di_output = self.model.predict(input_generator, verbose=2)\n",
    "\n",
    "        out_traces = input_generator.reshape_output(di_output)\n",
    "\n",
    "        if true_start_frame != start_frame: # related to the restriction to be applied from the start and end frames around 0 and end\n",
    "            out_traces = np.concatenate(\n",
    "                (array_to_append_front, out_traces), axis=0)\n",
    "\n",
    "        if true_end_frame != end_frame:\n",
    "            out_traces = np.concatenate(\n",
    "                (out_traces, array_to_append_back), axis=0)\n",
    "\n",
    "        return out_traces[:, channel_indices]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepInterpolatedRecording(BasePreprocessor):\n",
    "    name = 'deepinterpolate'\n",
    "\n",
    "    def __init__(self, recording, model_path: str,\n",
    "                 pre_frames: int = 30, post_frames: int = 30, pre_post_omission: int = 1,\n",
    "                 batch_size=128, use_gpu: bool = True, disable_tf_logger: bool = True):\n",
    "        assert has_tf(\n",
    "            use_gpu, disable_tf_logger), \"To use DeepInterpolation, you first need to install `tensorflow`.\"\n",
    "        \n",
    "        self.tf = import_tf(use_gpu, disable_tf_logger)\n",
    "        \n",
    "        # try move model load here with spawn\n",
    "        BasePreprocessor.__init__(self, recording)\n",
    "\n",
    "        # first time retrieving traces check that dimensions are ok\n",
    "        keras.backend.clear_session()\n",
    "        model = keras.models.load_model(filepath=model_path)\n",
    "\n",
    "        # check shape (this will need to be done at inference)\n",
    "        network_input_shape = model.get_config()[\"layers\"][0][\"config\"][\"batch_input_shape\"]\n",
    "        desired_shape = network_input_shape[1:3]\n",
    "        assert desired_shape[0]*desired_shape[1] == recording.get_num_channels(), \"text\"\n",
    "        assert network_input_shape[-1] == pre_frames + post_frames\n",
    "\n",
    "\n",
    "        # local_data = get_random_data_chunks(\n",
    "        #    recording, **random_chunk_kwargs)\n",
    "        # if isinstance(recording, ZeroChannelPaddedRecording):\n",
    "        #    local_data = local_data[:, recording.channel_mapping]\n",
    "\n",
    "        # local_mean = np.mean(local_data.flatten())\n",
    "        # local_std = np.std(local_data.flatten())\n",
    "        self.model = model\n",
    "        # add segment\n",
    "        for segment in recording._recording_segments:\n",
    "            recording_segment = DeepInterpolatedRecordingSegment(segment, self.model,\n",
    "                                                                 pre_frames, post_frames, pre_post_omission,\n",
    "                                                                 batch_size, use_gpu,\n",
    "                                                                 disable_tf_logger, desired_shape)\n",
    "            self.add_recording_segment(recording_segment)\n",
    "\n",
    "        self._preferred_mp_context = \"spawn\"\n",
    "        self._kwargs = dict(recording=recording.to_dict(), model_path=model_path,\n",
    "                            pre_frames=pre_frames, post_frames=post_frames, pre_post_omission=pre_post_omission,\n",
    "                            batch_size=batch_size, desired_shape=desired_shape, use_gpu=use_gpu,\n",
    "                            disable_tf_logger=disable_tf_logger)\n",
    "        self.extra_requirements.extend(['tensorflow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bandpass then Deepinterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of the training_bp_filter_t20s_v0.5s\n",
    "model_path = \"/home/buccino/codes/ephys-deepinterpolation/spikeinterface/deepinterpolation_recording/trained_models/test_training_bp_filter_t20s_v0.5s/first_test_unet_single_ephys_1024_mean_absolute_error_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_di_bp = DeepInterpolatedRecording(rec_norm_bp, model_path=model_path, pre_frames=30, \n",
    "                                   post_frames=30, pre_post_omission=1, disable_tf_logger=True,\n",
    "                                   use_gpu=True)\n",
    "print(rec_di_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_or = rec_norm_bp.get_traces(start_frame=3000, end_frame=13005)\n",
    "traces_or.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_bp_di = rec_di_bp.get_traces(start_frame=3000, end_frame=13005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharex=True, sharey=True, figsize=(25, 25))\n",
    "\n",
    "diff_bp_di = traces_or - traces_bp_di\n",
    "\n",
    "ax1.imshow(traces_or[:600].T)\n",
    "ax2.imshow(traces_bp_di[:600].T)\n",
    "ax3.imshow(diff_bp_di[:600].T)\n",
    "\n",
    "ax1.set_xlabel('Sample index')\n",
    "ax1.set_ylabel('Electrode channel')\n",
    "ax1.set_title('Original Recording')\n",
    "\n",
    "ax2.set_xlabel('Sample index')\n",
    "ax2.set_ylabel('Electrode channel')\n",
    "ax2.set_title('Predicted Recording (Bandpass then Deepinterpolation)')\n",
    "\n",
    "ax3.set_xlabel('Sample index')\n",
    "ax3.set_ylabel('Electrode channel')\n",
    "ax3.set_title('Difference between Original and Predicted Recording')\n",
    "\n",
    "fig.suptitle('Comparison between original and predicted -bandpass then deepinterpolation filtering- segment, for Neuropixels2.0')\n",
    "plt.subplots_adjust(top=1.65)\n",
    "\n",
    "#plt.savefig('/home/buccino/Visual Results/Spikeinterface/Neuropixels1.0/Visual graph/Comparison between original and predicted -bandpass then deepinterpolation filtering- segment, for Neuropixels2.0 recording.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Amplitude difference between original and predicted (bandpass then deepinterpolation)\" \n",
    "          \"\\n recording at channel number 146, for Neuropixels2.0 \\n \\n\", fontsize=10, loc='center')\n",
    "plt.plot(traces_or[:, 145], label=\"original\"), # blue is for original recording\n",
    "plt.plot(traces_bp_di[:, 145], label=\"Predicted\"), #orange is for for filtered signal\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "\n",
    "#plt.savefig('/home/buccino/Visual Results/Spikeinterface/Neuropixels1.0/Amplitude/original and predicted (bandpass then deepinterpolation).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_bp_di dimensions (10005, 384)\n",
    "diff_bp_di=diff_bp_di\n",
    "# Calculate the sum of all rows using np.sum() with axis=1\n",
    "average_diff_bp_di = np.mean(diff_bp_di, axis=1)\n",
    "#if the shape is (384,) and not (10005,), rerun the cell\n",
    "diff_bp_di.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_bp_di.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= average_diff_bp_di\n",
    "fs= 30000\n",
    "f, Pxx = signal.welch(x, fs=fs)\n",
    "\n",
    "# Plot the power spectrum density\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(f, Pxx,   label='bandpass then deepinterpolation')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Amplitude (dB)')\n",
    "ax.set_title('Power Spectral Density of the difference between the amplitude of original and predictive -bandpass then deepinterpolation- values\\n' \n",
    "             \"of the same recording segment over 10005 samples,for Neuropixels2.0 \\n\", size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate covariance matrix\n",
    "covariance_matrix = np.cov(diff_bp_di.T)\n",
    "\n",
    "# Plot covariance matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(covariance_matrix, cmap='coolwarm')\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.title(\" Covariance matrix of the difference between the amplitude of original and predictive -bandpass then deepinterpolation- values\\n\" \n",
    "             \"of the same recording segment over 10005 samples,for Neuropixels2.0 \\n\", size=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deepinterpolation then Bandpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_filter = \"/home/buccino/codes/ephys-deepinterpolation/spikeinterface/deepinterpolation_recording/trained_models/test_training_no_hp_filter_t20s_v0.5s/first_test_unet_single_ephys_1024_mean_absolute_error_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_norm_no_bp = spre.bandpass_filter(rec_norm_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_di_no = DeepInterpolatedRecording(rec_norm_no, model_path=model_no_filter, pre_frames=30, \n",
    "                                      post_frames=30, pre_post_omission=1, disable_tf_logger=True,\n",
    "                                      use_gpu=True)\n",
    "rec_di_no_bp = spre.bandpass_filter(rec_di_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_or_bp = rec_norm_no_bp.get_traces(start_frame=3000, end_frame=13005)\n",
    "traces_di_bp1 = rec_di_no_bp.get_traces(start_frame=3000, end_frame=13005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharex=True, sharey=True, figsize=(25, 25))\n",
    "\n",
    "diff_di_bp1 = traces_or_bp - traces_di_bp1\n",
    "\n",
    "ax1.imshow(traces_or_bp[:600].T)\n",
    "ax2.imshow(traces_di_bp1[:600].T)\n",
    "ax3.imshow(diff_di_bp1[:600].T)\n",
    "\n",
    "ax1.set_xlabel('Sample index')\n",
    "ax1.set_ylabel('Electrode channel')\n",
    "ax1.set_title('Original Recording')\n",
    "\n",
    "ax2.set_xlabel('Sample index')\n",
    "ax2.set_ylabel('Electrode channel')\n",
    "ax2.set_title('Predicted Recording (Deepinterpolation then bandpass)')\n",
    "\n",
    "ax3.set_xlabel('Sample index')\n",
    "ax3.set_ylabel('Electrode channel')\n",
    "ax3.set_title('Difference between Original and Predicted Recording')\n",
    "\n",
    "fig.suptitle('Comparison between original and predicted -deepinterpolation then bandpass filtering- segment, for Neuropixels2.0')\n",
    "plt.subplots_adjust(top=1.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Amplitudes of original and Predicted (deepinterpolation and then bandpass)\" \n",
    "          \"\\n recording segment at channel number 146, for Neuropixels2.0 \\n \\n\", fontsize=10, loc='center')\n",
    "plt.plot(traces_or_bp[:, 145], label=\"original\"), # blue is for original recording\n",
    "plt.plot(traces_di_bp1[:, 145], label=\"Prediction\"), #orange is for for filtered signal\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "#plt.savefig('/home/buccino/Visual Results/Spikeinterface/Neuropixels1.0/Visual graph/Comparison between original and Predicted -deepinterpolation then bandpass- segment, for Neuropixels2.0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_bp_di dimensions (10005, 384)\n",
    "diff_di_bp1 = diff_di_bp1\n",
    "diff_di_bp1.shape\n",
    "# Calculate the sum of all rows using np.sum() with axis=1\n",
    "average_diff_di_bp1 = np.mean(diff_di_bp1, axis=1)\n",
    "average_diff_di_bp1.shape\n",
    "#if the shape is (384,) and not (10005,), rerun the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "x= average_diff_di_bp1\n",
    "fs= 30000\n",
    "f, Pxx = signal.welch(x, fs=fs)\n",
    "\n",
    "# Plot the power spectrum density\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(f, Pxx,   label='bandpass then deepinterpolation')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Amplitude (dB)')\n",
    "ax.set_title('Power Spectral Density of the difference between the amplitude of original and predictive -bandpass then deepinterpolation- values\\n' \n",
    "             \"of the same recording segment over 10005 samples,for Neuropixels2.0 \\n\", size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix\n",
    "# Calculate covariance matrix\n",
    "covariance_matrix = np.cov(diff_di_bp1.T)\n",
    "\n",
    "# Plot covariance matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(covariance_matrix, cmap='coolwarm')\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.title(\" Covariance matrix of the difference between the amplitude of original and predictive -deepinterpolation then bandpass- values\\n\" \n",
    "             \"of the same recording segment over 10005 samples,for Neuropixels2.0 \\n\", size=8)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highpass then deepinterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hp_filter = \"/home/buccino/codes/ephys-deepinterpolation/spikeinterface/deepinterpolation_recording/trained_models/test_training_hp_filter_t20s_v0.5s/first_test_unet_single_ephys_1024_mean_absolute_error_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_di_hp = DeepInterpolatedRecording(rec_norm_hp, model_path=model_hp_filter, pre_frames=30, \n",
    "                                      post_frames=30, pre_post_omission=1, disable_tf_logger=True,\n",
    "                                      use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_or = rec_norm_hp.get_traces(start_frame=3000, end_frame=13005)\n",
    "traces_hp_di = rec_di_hp.get_traces(start_frame=3000, end_frame=13005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharex=True, sharey=True, figsize=(25, 25))\n",
    "\n",
    "diff_hp_di = traces_or - traces_hp_di\n",
    "\n",
    "ax1.imshow(traces_or[:600].T)\n",
    "ax2.imshow(traces_hp_di[:600].T)\n",
    "ax3.imshow(diff_hp_di[:600].T)\n",
    "\n",
    "ax1.set_xlabel('Sample index')\n",
    "ax1.set_ylabel('Electrode channel')\n",
    "ax1.set_title('Original Recording')\n",
    "\n",
    "ax2.set_xlabel('Sample index')\n",
    "ax2.set_ylabel('Electrode channel')\n",
    "ax2.set_title('Predicted Recording (Highpass then Deepinterpolation)')\n",
    "\n",
    "ax3.set_xlabel('Sample index')\n",
    "ax3.set_ylabel('Electrode channel')\n",
    "ax3.set_title('Difference between Original and Predicted Recording')\n",
    "\n",
    "fig.suptitle('Comparison between original and Predicted -highpass then deepinterpolation- segment, for Neuropixels2.0')\n",
    "plt.subplots_adjust(top=1.65)\n",
    "\n",
    "#plt.savefig('/home/buccino/Visual Results/Spikeinterface/Neuropixels1.0/Visual graph/Comparison between original and Predicted -highpass then deepinterpolation- segment, for Neuropixels2.0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Amplitude difference between original and filtered (highpass then deepinterpolation)\" \n",
    "          \"\\n at channel number 146, for Neuropixels2.0 \\n \\n\", fontsize=10, loc='center')\n",
    "plt.plot(traces_or[:, 145], label=\"original\"), # blue is for original recording\n",
    "plt.plot(traces_hp_di[:, 145], label=\"Predicated\"), #orange is for for filtered signal\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "#plt.savefig('/home/buccino/Visual Results/Spikeinterface/Neuropixels1.0/Amplitude/original and filtered (highpass then deepinterpolation).png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_bp_di dimensions (10005, 384)\n",
    "diff_hp_di = diff_hp_di\n",
    "\n",
    "# Calculate the sum of all rows using np.sum() with axis=1\n",
    "average_diff_hp_di = np.mean(diff_hp_di, axis=1)\n",
    "average_diff_hp_di.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= average_diff_hp_di\n",
    "fs= 30000\n",
    "f, Pxx = signal.welch(x, fs=fs)\n",
    "\n",
    "# Plot the power spectrum density\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(f, Pxx,   label='bandpass then deepinterpolation')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Amplitude (dB)')\n",
    "ax.set_title('Power Spectral Density of the difference between the amplitude of original and predictive -bandpass then deepinterpolation- values\\n' \n",
    "             \"of the same recording segment over 10005 samples,for Neuropixels2.0 \\n\", size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix\n",
    "\n",
    "# Convert neural recording to numpy array\n",
    "neural_array = np.array(recording_hp.get_traces(end_frame=30000))\n",
    "\n",
    "# Transpose the array so that each row is a channel and each column is a time point\n",
    "neural_array = neural_array.T\n",
    "\n",
    "# Calculate covariance matrix\n",
    "covariance_matrix = np.cov(neural_array)\n",
    "\n",
    "# Plot covariance matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(covariance_matrix, cmap='coolwarm')\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.title(\" Covariance matrix of the difference between the amplitude of original and predictive -highpass then deepinterpolation- values\\n\" \n",
    "             \"of the same recording segment over 10005 samples,for Neuropixels2.0 \\n\", size=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 30000 # Sampling frequency\n",
    "N = 10005 # Number of samples\n",
    "t = np.linspace(0, N/fs, N)\n",
    "\n",
    "x= average_diff_bp_di\n",
    "x1= average_diff_di_bp1\n",
    "x2= average_diff_hp_di\n",
    "\n",
    "# Calculate the power spectrum density using Welch's method\n",
    "f, Pxx = signal.welch(x, fs=fs, nperseg=256)\n",
    "f1, Pxx1 = signal.welch(x1, fs=fs, nperseg=256)\n",
    "f2, Pxx2 = signal.welch(x2, fs=fs, nperseg=256)\n",
    "\n",
    "# Plot the power spectrum density\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(f, Pxx,   label='bandpass then deepinterpolation')\n",
    "ax.semilogy(f, Pxx1, label='deepinterpolation then bandpass')\n",
    "ax.semilogy(f, Pxx2, label='highpass then deepinterpolation')\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Amplitude (dB)')\n",
    "ax.set_title('Power Spectral Density of the difference between the amplitude of original and different predictive processing modalities\\n' \n",
    "             \"of the same recording segment,for Neuropixels2.0 \\n\", size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov1 = np.cov(diff_bp_di.T)\n",
    "cov2 = np.cov(diff_di_bp1.T)\n",
    "cov3 = np.cov(diff_hp_di.T)\n",
    "\n",
    "# Plot covariance matrices\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25, 25))\n",
    "\n",
    "im1 = axs[0].imshow(cov1, cmap='coolwarm')\n",
    "axs[0].set_title('Bandpass then Deepinterpolation Error Covariance')\n",
    "axs[0].set_xlabel('channel index')\n",
    "axs[0].set_ylabel('channel index')\n",
    "fig.colorbar(im1, ax=axs[0], shrink=0.2)\n",
    "\n",
    "im2 = axs[1].imshow(cov2, cmap='coolwarm')\n",
    "axs[1].set_title('Deepinterpolation then Bandpass Error Covariance')\n",
    "axs[1].set_xlabel('channel index')\n",
    "axs[1].set_ylabel('channel index')\n",
    "fig.colorbar(im2, ax=axs[1], shrink=0.2)\n",
    "\n",
    "im3 = axs[2].imshow(cov3, cmap='coolwarm')\n",
    "axs[2].set_title('Highpass then Deepinterpolation Error Covariance')\n",
    "axs[2].set_xlabel('channel index')\n",
    "axs[2].set_ylabel('channel index')\n",
    "fig.colorbar(im3, ax=axs[2], shrink=0.2)\n",
    "\n",
    "#plt.title('Covariance matrices of the difference between the amplitude of original and different predictive processing modalities\\n' \n",
    "#             \"of the same recording segment,for Neuropixels2.0 \\n\", size=10, loc= 'center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, kstest\n",
    "\n",
    "x= average_diff_bp_di\n",
    "x1= average_diff_di_bp1\n",
    "x2= average_diff_hp_di\n",
    "\n",
    "mu = np.mean(x)\n",
    "sigma = np.std(x)\n",
    "\n",
    "mu1 = np.mean(x1)\n",
    "sigma1 = np.std(x1)\n",
    "\n",
    "mu2 = np.mean(x2)\n",
    "sigma2 = np.std(x2)\n",
    "\n",
    "print('diff_bp_di: mean', mu, 'std-dev:', sigma)\n",
    "print('diff_di_bp: mean', mu1, 'std-dev:', sigma1)\n",
    "print('diff_hp_di: mean', mu2, 'std-dev:', sigma2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x2\n",
    "hist, bin_edges = np.histogram(data, bins=15, density=True)\n",
    "pdf = hist / np.sum(hist)\n",
    "\n",
    "# white noise\n",
    "white_noise = np.random.normal(0, 1, size=len(data))\n",
    "hist_white, bin_edges_white = np.histogram(white_noise, bins=20, density=True)\n",
    "pdf_white = hist_white / np.sum(hist_white)\n",
    "\n",
    "test_statistic, p_value = kstest(pdf, pdf_white)\n",
    "\n",
    "\n",
    "plt.plot(bin_edges[:-1], pdf, label='diff_hp_di')\n",
    "plt.plot(bin_edges_white[:-1], pdf_white, label='White Noise')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Comparison of PDFs')\n",
    "plt.legend()\n",
    "plt.text(0.1, 0.9, 'p-value of KS test: {:.2f}'.format(p_value), transform=plt.gca().transAxes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
